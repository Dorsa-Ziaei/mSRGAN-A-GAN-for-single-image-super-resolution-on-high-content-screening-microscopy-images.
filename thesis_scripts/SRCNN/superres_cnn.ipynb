{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "#import cPickle as pkl\n",
    "import _pickle as cPickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "import glob\n",
    "%matplotlib inline  \n",
    "print (\"Packages loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dirpath = \"/home/saurabh/Documents/data/iccv09Data/images/\"\n",
    "#logs_path = \"/home/saurabh/Documents/data/iccv09Data/images/\"\n",
    "height = 240\n",
    "width  = 320\n",
    "resize_ratio = 4\n",
    "nr_img = 0\n",
    "fileList = glob.glob(dirpath + '*.jpg')\n",
    "for i, file in enumerate(fileList):\n",
    "    img = Image.open(file)\n",
    "    array = np.array(img) \n",
    "    if array.shape[0] == height and array.shape[1] == width:\n",
    "        nr_img = nr_img + 1\n",
    "        rgb = array.reshape(1, height, width, 3)\n",
    "        imglow = img.resize((int(width/resize_ratio)\n",
    "                ,int(height/resize_ratio)), Image.BICUBIC)\n",
    "        imglow = imglow.resize((width, height), Image.BICUBIC)\n",
    "        rgblow = np.array(np.float32(imglow)/255.)\n",
    "        rgblow = rgblow.reshape(1, height, width, 3)\n",
    "        rgb = np.reshape(rgb, [1, -1])\n",
    "        rgblow = np.reshape(rgblow, [1, -1])\n",
    "        if nr_img == 1:\n",
    "            data = rgb\n",
    "            datalow = rgblow\n",
    "        else:\n",
    "            data = np.concatenate((data, rgb), axis=0)\n",
    "            datalow = np.concatenate((datalow, rgblow), axis=0)\n",
    "        \n",
    "print (\"nr_img is %d\" % (nr_img))\n",
    "print (\"Shape of 'data' is %s\" % (data.shape,))\n",
    "print (\"Shape of 'datalow' is %s\" % (datalow.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Divide into two sets\n",
    "## (xtrain, ytrain) and (xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "randidx = np.random.permutation(nr_img)\n",
    "nrtrain = int(nr_img*0.7)\n",
    "nrtest  = nr_img - nrtrain\n",
    "xtrain  = datalow[randidx[0:nrtrain], :]\n",
    "ytrain  = data[randidx[0:nrtrain], :]\n",
    "xtest   = datalow[randidx[nrtrain:nr_img], :]\n",
    "ytest   = data[randidx[nrtrain:nr_img], :]\n",
    "print (\"Shape of 'xtrain' is %s\" % (xtrain.shape,))\n",
    "print (\"Shape of 'ytrain' is %s\" % (ytrain.shape,))\n",
    "print (\"Shape of 'xtest' is %s\" % (xtest.shape,))\n",
    "print (\"Shape of 'ytest' is %s\" % (ytest.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Plot some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "randidx = np.random.randint(nrtrain)\n",
    "currx = xtrain[randidx, :]\n",
    "currx = np.reshape(currx, [height, width, 3])\n",
    "plt.imshow(currx)\n",
    "plt.title(\"Train input image\")\n",
    "plt.show()\n",
    "curry = ytrain[randidx, :]\n",
    "curry = np.reshape(curry, [height, width, 3])\n",
    "plt.imshow(curry)\n",
    "plt.title(\"Train output image\")\n",
    "plt.show() \n",
    "# Test\n",
    "randidx = np.random.randint(nrtest)\n",
    "currx = xtest[randidx, :]\n",
    "currx = np.reshape(currx, [height, width, 3])\n",
    "plt.imshow(currx)\n",
    "plt.title(\"Test input image\")\n",
    "plt.show()\n",
    "curry = ytest[randidx, :]\n",
    "curry = np.reshape(curry, [height, width, 3])\n",
    "plt.imshow(curry)\n",
    "plt.title(\"Test output image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n1 = 32\n",
    "n2 = 64\n",
    "n3 = 64\n",
    "n4 = 64\n",
    "n5 = 64\n",
    "n6 = 3\n",
    "ksize = 3\n",
    "weights = {\n",
    "    'ce1': tf.Variable(tf.random_normal([ksize, ksize, 3, n1],  stddev=0.01)),\n",
    "    'ce2': tf.Variable(tf.random_normal([ksize, ksize, n1, n2], stddev=0.01)),\n",
    "    'ce3': tf.Variable(tf.random_normal([ksize, ksize, n2, n3], stddev=0.01)),\n",
    "    'ce4': tf.Variable(tf.random_normal([ksize, ksize, n3, n4], stddev=0.01)),\n",
    "    'ce5': tf.Variable(tf.random_normal([ksize, ksize, n4, n5], stddev=0.01)),\n",
    "    'ce6': tf.Variable(tf.random_normal([ksize, ksize, n5, n6],  stddev=0.01))\n",
    "}\n",
    "biases = {\n",
    "    'be1': tf.Variable(tf.random_normal([n1], stddev=0.01)),\n",
    "    'be2': tf.Variable(tf.random_normal([n2], stddev=0.01)),\n",
    "    'be3': tf.Variable(tf.random_normal([n3], stddev=0.01)),\n",
    "    'be4': tf.Variable(tf.random_normal([n4], stddev=0.01)),\n",
    "    'be5': tf.Variable(tf.random_normal([n5], stddev=0.01)),\n",
    "    'be6': tf.Variable(tf.random_normal([n6], stddev=0.01))\n",
    "}\n",
    "def srn(_X, _W, _b, _keepprob):\n",
    "    _input_r = tf.reshape(_X, shape=[-1, height, width, 3])\n",
    "    # Encoder\n",
    "    _ce1 = tf.nn.relu(tf.add(tf.nn.conv2d(_input_r, _W['ce1']\n",
    "        , strides=[1, 1, 1, 1], padding='SAME'), _b['be1']))\n",
    "    _ce1 = tf.nn.dropout(_ce1, _keepprob)\n",
    "    _ce2 = tf.nn.relu(tf.add(tf.nn.conv2d(_ce1, _W['ce2']\n",
    "        , strides=[1, 1, 1, 1], padding='SAME'), _b['be2'])) \n",
    "    _ce2 = tf.nn.dropout(_ce2, _keepprob)\n",
    "    _ce3 = tf.nn.relu(tf.add(tf.nn.conv2d(_ce2, _W['ce3']\n",
    "        , strides=[1, 1, 1, 1], padding='SAME'), _b['be3'])) \n",
    "    _ce3 = tf.nn.dropout(_ce3, _keepprob)\n",
    "    \n",
    "    _ce4 = tf.nn.relu(tf.add(tf.nn.conv2d(_ce3, _W['ce4']\n",
    "        , strides=[1, 1, 1, 1], padding='SAME'), _b['be4']))\n",
    "    _ce4 = tf.nn.dropout(_ce4, _keepprob)\n",
    "    _ce5 = tf.nn.relu(tf.add(tf.nn.conv2d(_ce4, _W['ce5']\n",
    "        , strides=[1, 1, 1, 1], padding='SAME'), _b['be5'])) \n",
    "    _ce5 = tf.nn.dropout(_ce5, _keepprob)\n",
    "    _ce6 = tf.nn.relu(tf.add(tf.nn.conv2d(_ce5, _W['ce6']\n",
    "        , strides=[1, 1, 1, 1], padding='SAME'), _b['be6'])) \n",
    "    _out = _ce6 + _input_r\n",
    "    return {'input_r': _input_r, 'ce1': _ce1, 'ce2': _ce2, 'ce3': _ce3\n",
    "        , 'ce4': _ce4, 'ce5': _ce5, 'ce6': _ce6\n",
    "        , 'layers': (_input_r, _ce1, _ce2, _ce3, _ce4, _ce5, _ce6)\n",
    "        , 'out': _out}\n",
    "print (\"Network ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dim = height*width*3\n",
    "x = tf.placeholder(tf.float32, [None, dim])\n",
    "y = tf.placeholder(tf.float32, [None, dim])\n",
    "keepprob = tf.placeholder(tf.float32)\n",
    "pred = srn(x, weights, biases, keepprob)['out']\n",
    "cost = tf.reduce_mean(tf.square(srn(x, weights, biases, keepprob)['out'] \n",
    "            - tf.reshape(y, shape=[-1, height, width, 3])))\n",
    "\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "optm = tf.train.AdamOptimizer(learning_rate, 0.9).minimize(cost)\n",
    "init = tf.initialize_all_variables()\n",
    "print (\"Functions ready\")\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "#summary_writer = tf.summary.FileWriter('/tmp/tensorflow_logs', graph=sess.graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strart training..\n",
      "Training dataset\n",
      "[00/1000000] Training cost: 13819.9375\n",
      "Test dataset\n",
      "[00/1000000] Test cost: 22676.9805\n",
      "Training dataset\n",
      "[100/1000000] Training cost: 995.1548\n",
      "Test dataset\n",
      "[100/1000000] Test cost: 1338.0475\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# Fit all training data\n",
    "batch_size = 1\n",
    "n_epochs   = 1000000\n",
    "print(\"Strart training..\")\n",
    "randidx = np.random.randint(nrtrain, size=batch_size)\n",
    "batch_xs = xtrain[randidx, :]\n",
    "batch_ys = ytrain[randidx, :]\n",
    "train_error = []\n",
    "test_error = []\n",
    "\n",
    "summary_writer = tf.summary.FileWriter('/tmp/tensorflow_logs',sess.graph)\n",
    "#tf.global_variables_initializer\n",
    "\n",
    "#summary_writer = tf.summary.FileWriter('/tmp/tensorflow_logs', graph=tf.get_default_graph())\n",
    "\n",
    "\n",
    "for epoch_i in range(n_epochs):\n",
    "    total_batch = int(nrtrain // batch_size)\n",
    "    for batch_i in range(nrtrain // batch_size):\n",
    "        randidx = np.random.randint(nrtrain, size=batch_size)\n",
    "        batch_xs = xtrain[randidx, :]\n",
    "        batch_ys = ytrain[randidx, :]\n",
    "        sess.run(optm, feed_dict={x: batch_xs\n",
    "            , y: batch_ys, keepprob: 0.7})\n",
    "        \n",
    "        #summary = sess.run([merged_summary_op], feed_dict={x: train_xs, y: train_ys, keepprob: 1.})\n",
    "        #summary_writer.add_summary(summary, epoch_i)\n",
    "        \n",
    "        \n",
    "        #summary = sess.run(merged_summary_op, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        \n",
    "        #summary_writer.add_summary(summary, epoch_i * total_batch + batch_i)\n",
    "    \n",
    "    if (epoch_i % 100) == 0:\n",
    "        n_examples = 2\n",
    "        print (\"Training dataset\")\n",
    "        randidx = np.random.randint(nrtrain, size=n_examples)\n",
    "        train_xs = xtrain[randidx, :]\n",
    "        train_ys = ytrain[randidx, :]\n",
    "        recon = sess.run(pred, feed_dict={x: train_xs, keepprob: 1.})\n",
    "        print (\"[%02d/%02d] Training cost: %.4f\" % (epoch_i, n_epochs\n",
    "            , sess.run(cost, feed_dict={x: train_xs\n",
    "            , y: train_ys, keepprob: 1.})))\n",
    "        \n",
    "        \n",
    "        \n",
    "        c = sess.run(cost, feed_dict={x: train_xs , y: train_ys, keepprob: 1.})\n",
    "        train_error.append(c)\n",
    "        \n",
    "        #c = sess.run([cost],feed_dict={x: train_xs, y: train_ys})\n",
    "        \n",
    "        #summary_writer.add_summary(summary, cost, epoch_i, n_epochs)\n",
    "        \n",
    "        #fig, axs = plt.subplots(3, n_examples, figsize=(15, 20))\n",
    "        #for example_i in range(n_examples):\n",
    "         #   axs[0][example_i].imshow(np.reshape(\n",
    "              #  train_xs[example_i, :], (height, width, 3)))\n",
    "            #axs[1][example_i].imshow(np.reshape(\n",
    "               # recon[example_i, :], (height, width, 3)))\n",
    "            #axs[2][example_i].imshow(np.reshape(\n",
    "                #train_ys[example_i, :], (height, width, 3)))\n",
    "        \n",
    "        \n",
    "        #plt.show()\n",
    "        print (\"Test dataset\")\n",
    "        randidx = np.random.randint(nrtest, size=n_examples)\n",
    "        test_xs = xtest[randidx, :]\n",
    "        test_ys = ytest[randidx, :]\n",
    "        recon = sess.run(pred, feed_dict={x: test_xs, keepprob: 1.})\n",
    "        print (\"[%02d/%02d] Test cost: %.4f\" % (epoch_i, n_epochs\n",
    "            , sess.run(cost, feed_dict={x: test_xs\n",
    "            , y: test_ys, keepprob: 1.})))\n",
    "        c2 = sess.run(cost, feed_dict={x: test_xs , y: test_ys, keepprob: 1.})\n",
    "        test_error.append(c2)\n",
    "\n",
    "        #fig, axs = plt.subplots(3, n_examples, figsize=(15, 20))\n",
    "        #for example_i in range(n_examples):\n",
    "            #axs[0][example_i].imshow(np.reshape(\n",
    "                #test_xs[example_i, :], (height, width, 3)))\n",
    "            #axs[1][example_i].imshow(np.reshape(\n",
    "                #recon[example_i, :], (height, width, 3)))\n",
    "            #axs[2][example_i].imshow(np.reshape(\n",
    "                #test_ys[example_i, :], (height, width, 3)))\n",
    "        plt.show()\n",
    "print(\"Training done. \")\n",
    "print(train_error)\n",
    "print(test_error)\n",
    "print (\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=/tmp/tensorflow_logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
